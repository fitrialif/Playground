{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent Neural Networks (RNN)\n",
    "=========\n",
    "March 8, 2019.\n",
    "\n",
    "Luis Da Silva.\n",
    "\n",
    "This notebook explores the use of RNN for text processing.\n",
    "\n",
    "Thanks to [Angelo Cangelosi](https://www.research.manchester.ac.uk/portal/angelo.cangelosi.html) for teaching me most of this material."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNs to Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading text file and converting to clean text**\n",
    "\n",
    "This code will read the file \"[alice_in_wonderland.txt](http://www.gutenberg.org/files/11/11-0.txt)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading text file...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading text file...\")\n",
    "\n",
    "INPUT_FILE = \"alice_in_wonderland.txt\"\n",
    "\n",
    "fin = open(INPUT_FILE, 'rb')\n",
    "lines = []\n",
    "for line in fin:\n",
    "    line = line.strip().lower()\n",
    "    line = line.decode(\"ascii\", \"ignore\")\n",
    "    if len(line) == 0:\n",
    "        continue\n",
    "    lines.append(line)\n",
    "fin.close()\n",
    "whole_text = \" \".join(lines)\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing characters look-up table...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing characters look-up table...\")\n",
    "\n",
    "chars = set([c for c in whole_text])\n",
    "nb_chars = len(chars)\n",
    "char2index = dict((c, i) for i, c in enumerate(chars))\n",
    "index2char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input text labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating input and label text...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating input and label text...\")\n",
    "\n",
    "SEQLEN = 10\n",
    "STEP = 1\n",
    "\n",
    "input_chars = []\n",
    "label_chars = []\n",
    "for i in range(0, len(whole_text) - SEQLEN, STEP):\n",
    "    input_chars.append(whole_text[i:i + SEQLEN])\n",
    "    label_chars.append(whole_text[i + SEQLEN])\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vectorisation of the input and output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing input and label text...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectorizing input and label text...\")\n",
    "\n",
    "X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
    "y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n",
    "for i, input_char in enumerate(input_chars):\n",
    "    for j, ch in enumerate(input_char):\n",
    "        X[i, j, char2index[ch]] = 1\n",
    "    y[i, char2index[label_chars[i]]] = 1\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple RNN Model definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 128)               23424     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 54)                6966      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 54)                0         \n",
      "=================================================================\n",
      "Total params: 30,390\n",
      "Trainable params: 30,390\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Definition of the network and training hyperparameters\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 512\n",
    "NUM_ITERATIONS = 25\n",
    "NUM_EPOCHS_PER_ITERATION = 1\n",
    "NUM_PREDS_PER_EPOCH = 100\n",
    "\n",
    "# Definition of the network topology, with simpleRNN hidden layer\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(HIDDEN_SIZE, return_sequences=False, input_shape=(SEQLEN, nb_chars), unroll=True))\n",
    "model.add(Dense(nb_chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n",
    "\n",
    "#show the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training and testing of the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Iteration #: 0\n",
      "Epoch 1/1\n",
      "158172/158172 [==============================] - 7s 43us/step - loss: 2.5619\n",
      "Generating from seed: de as she \n",
      "de as she sand the sathe sathe sathe sathe sathe sathe sathe sathe sathe sathe sathe sathe sathe sathe sathe s\n",
      "==================================================\n",
      "Iteration #: 1\n",
      "Epoch 1/1\n",
      "158172/158172 [==============================] - 3s 18us/step - loss: 2.1763\n",
      "Generating from seed: egun to th\n",
      "egun to the was the she sald the was the she sald the was the she sald the was the she sald the was the she sa\n",
      "==================================================\n",
      "Iteration #: 2\n",
      "Epoch 1/1\n",
      "158172/158172 [==============================] - 3s 18us/step - loss: 2.0710\n",
      "Generating from seed: -day? i sh\n",
      "-day? i she the ghe the ghe the ghe the ghe the ghe the ghe the ghe the ghe the ghe the ghe the ghe the ghe th\n",
      "==================================================\n",
      "Iteration #: 3\n",
      "Epoch 1/1\n",
      "158172/158172 [==============================] - 3s 18us/step - loss: 2.0058\n",
      "Generating from seed: g slowly b\n",
      "g slowly but in the the said the coust in the said the coust in the said the coust in the said the coust in th\n",
      "==================================================\n",
      "Iteration #: 4\n",
      "Epoch 1/1\n",
      "158172/158172 [==============================] - 3s 20us/step - loss: 1.9542\n",
      "Generating from seed: stard, pin\n",
      "stard, pind and the said the dont of the said the dont of the said the dont of the said the dont of the said t\n",
      "==================================================\n",
      "Iteration #: 5\n",
      "Epoch 1/1\n",
      "158172/158172 [==============================] - 3s 19us/step - loss: 1.9098\n",
      "Generating from seed: e was stan\n",
      "e was stant in a dore the said the mare the lack the lack the lack the lack the lack the lack the lack the lac\n",
      "==================================================\n",
      "Iteration #: 6\n",
      "Epoch 1/1\n",
      "158172/158172 [==============================] - 3s 18us/step - loss: 1.8692\n",
      "Generating from seed: se i can g\n",
      "se i can ghe the mous the marke was she was she was she was she was she was she was she was she was she was sh\n",
      "==================================================\n",
      "Iteration #: 7\n",
      "Epoch 1/1\n",
      "158172/158172 [==============================] - 3s 18us/step - loss: 1.8327\n",
      "Generating from seed:  stuff, th\n",
      " stuff, the groplent on the was the was the was the was the was the was the was the was the was the was the wa\n",
      "==================================================\n",
      "Iteration #: 8\n",
      "Epoch 1/1\n",
      "158172/158172 [==============================] - 3s 18us/step - loss: 1.7990\n",
      "Generating from seed: d not help\n",
      "d not help the mare the mouse for the project gutenberg-tm elect on the was the was the was the was the was th\n",
      "==================================================\n",
      "Iteration #: 9\n",
      "Epoch 1/1\n",
      "158172/158172 [==============================] - 3s 18us/step - loss: 1.7683\n",
      "Generating from seed: and went t\n",
      "and went the dorme said the donge she had she had she had she had she had she had she had she had she had she \n",
      "==================================================\n",
      "Iteration #: 10\n",
      "Epoch 1/1\n",
      "158172/158172 [==============================] - 3s 18us/step - loss: 1.7406\n",
      "Generating from seed:  she tried\n",
      " she tried the cares and the mare the was of the was of the was of the was of the was of the was of the was of\n",
      "==================================================\n",
      "Iteration #: 11\n",
      "Epoch 1/1\n",
      "158172/158172 [==============================] - 3s 18us/step - loss: 1.7150\n",
      "Generating from seed: e of her f\n",
      "e of her for the work on the work on the work on the work on the work on the work on the work on the work on t\n",
      "==================================================\n",
      "Iteration #: 12\n",
      "Epoch 1/1\n",
      "158172/158172 [==============================] - 3s 18us/step - loss: 1.6918\n",
      "Generating from seed: e other. i\n",
      "e other. it was the dont was the dont was the dont was the dont was the dont was the dont was the dont was the\n",
      "==================================================\n",
      "Iteration #: 13\n",
      "Epoch 1/1\n",
      "158172/158172 [==============================] - 3s 18us/step - loss: 1.6711\n",
      "Generating from seed: d quite sl\n",
      "d quite sle the more the dormouse the dormouse the dormouse the dormouse the dormouse the dormouse the dormous\n",
      "==================================================\n",
      "Iteration #: 14\n",
      "Epoch 1/1\n",
      "158172/158172 [==============================] - 3s 18us/step - loss: 1.6516\n",
      "Generating from seed: t as well \n",
      "t as well the gryphon a grown the project gutenberg-tm electronic works and the project gutenberg-tm electroni\n",
      "==================================================\n",
      "Iteration #: 15\n",
      "Epoch 1/1\n",
      "158172/158172 [==============================] - 3s 18us/step - loss: 1.6331\n",
      "Generating from seed: e had alre\n",
      "e had alrer a dont the was she was a little the was she was a little the was she was a little the was she was \n",
      "==================================================\n",
      "Iteration #: 16\n",
      "Epoch 1/1\n",
      "158172/158172 [==============================] - 3s 18us/step - loss: 1.6164\n",
      "Generating from seed: bottom of \n",
      "bottom of the was so she was a little that she was a little that she was a little that she was a little that s\n",
      "==================================================\n",
      "Iteration #: 17\n",
      "Epoch 1/1\n",
      "158172/158172 [==============================] - 3s 18us/step - loss: 1.6002\n",
      "Generating from seed: claimed al\n",
      "claimed alice was the mouse said the docalice said the docalice said the docalice said the docalice said the d\n",
      "==================================================\n",
      "Iteration #: 18\n",
      "Epoch 1/1\n",
      "158172/158172 [==============================] - 3s 18us/step - loss: 1.5852\n",
      "Generating from seed: r--and cam\n",
      "r--and came the mouse of the was so mant in the mouse of the was so mant in the mouse of the was so mant in th\n",
      "==================================================\n",
      "Iteration #: 19\n",
      "Epoch 1/1\n",
      "158172/158172 [==============================] - 3s 18us/step - loss: 1.5717\n",
      "Generating from seed: declared f\n",
      "declared for the project gutenberg-tm electronic works on the was so the project gutenberg-tm electronic works\n",
      "==================================================\n",
      "Iteration #: 20\n",
      "Epoch 1/1\n",
      "158172/158172 [==============================] - 3s 19us/step - loss: 1.5588\n",
      "Generating from seed:  is this? \n",
      " is this? i said the dormouse said the dormouse said the dormouse said the dormouse said the dormouse said the\n",
      "==================================================\n",
      "Iteration #: 21\n",
      "Epoch 1/1\n",
      "158172/158172 [==============================] - 3s 19us/step - loss: 1.5457\n",
      "Generating from seed:  well! wha\n",
      " well! what the gryphon whith reand the dormouse the dormouse the dormouse the dormouse the dormouse the dormo\n",
      "==================================================\n",
      "Iteration #: 22\n",
      "Epoch 1/1\n",
      "158172/158172 [==============================] - 3s 19us/step - loss: 1.5346\n",
      "Generating from seed: as much pl\n",
      "as much please to enee the courd and the courd and the courd and the courd and the courd and the courd and the\n",
      "==================================================\n",
      "Iteration #: 23\n",
      "Epoch 1/1\n",
      "158172/158172 [==============================] - 3s 20us/step - loss: 1.5234\n",
      "Generating from seed: ust obtain\n",
      "ust obtain the courd and herself it and alice was so she went on a conger alice, and she was the formouse she \n",
      "==================================================\n",
      "Iteration #: 24\n",
      "Epoch 1/1\n",
      "158172/158172 [==============================] - 3s 19us/step - loss: 1.5130\n",
      "Generating from seed: hat i see \n",
      "hat i see said the mock turtle said the mock turtle said the mock turtle said the mock turtle said the mock tu\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(NUM_ITERATIONS):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Iteration #: %d\" % (iteration))\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    "    \n",
    "    # testing model\n",
    "    # randomly choose a row from input_chars, then use it to \n",
    "    # generate text from model for next 100 chars\n",
    "    test_idx = np.random.randint(len(input_chars))\n",
    "    test_chars = input_chars[test_idx]\n",
    "    print(\"Generating from seed: %s\" % (test_chars))\n",
    "    print(test_chars, end=\"\")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "        Xtest = np.zeros((1, SEQLEN, nb_chars))\n",
    "        for i, ch in enumerate(test_chars):\n",
    "            Xtest[0, i, char2index[ch]] = 1\n",
    "        pred = model.predict(Xtest, verbose=0)[0]\n",
    "        ypred = index2char[np.argmax(pred)]\n",
    "        print(ypred, end=\"\")\n",
    "        # move forward with test_chars + ypred\n",
    "        test_chars = test_chars[1:] + ypred\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM for Sentiment Analysis\n",
    "========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Activation, Dense, Dropout, SpatialDropout1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = \"umich-sentiment-train.txt\"\n",
    "\n",
    "EMBEDDING_SIZE = 128\n",
    "HIDDEN_LAYER_SIZE = 64\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis of words in corpus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "2311\n"
     ]
    }
   ],
   "source": [
    "# Read training data and generate vocabulary\n",
    "maxlen = 0\n",
    "word_freqs = collections.Counter()\n",
    "num_recs = 0\n",
    "\n",
    "ftrain = open(INPUT_FILE, 'rb')\n",
    "for line in ftrain:\n",
    "    label, sentence = line.strip().split(b\"\\t\")\n",
    "    words = nltk.word_tokenize(sentence.decode(\"ascii\", \"ignore\").lower())\n",
    "    if len(words) > maxlen:\n",
    "        maxlen = len(words)\n",
    "    for word in words:\n",
    "        word_freqs[word] += 1\n",
    "    num_recs += 1\n",
    "ftrain.close()\n",
    "\n",
    "## Get some information about our corpus\n",
    "print (maxlen)            # 42\n",
    "print (len(word_freqs))   # 2313"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unkown word and padding word and lookup tables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 2000\n",
    "MAX_SENTENCE_LENGTH = 40\n",
    "\n",
    "# 1 is UNK, 0 is PAD\n",
    "# We take MAX_FEATURES-1 featurs to accound for PAD\n",
    "vocab_size = min(MAX_FEATURES, len(word_freqs)) + 2\n",
    "word2index = {x[0]: i+2 for i, x in \n",
    "                enumerate(word_freqs.most_common(MAX_FEATURES))}\n",
    "word2index[\"PAD\"] = 0\n",
    "word2index[\"UNK\"] = 1\n",
    "index2word = {v:k for k, v in word2index.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare training sequences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5668, 40) (1418, 40) (5668,) (1418,)\n"
     ]
    }
   ],
   "source": [
    "# convert sentences to sequences\n",
    "X = np.empty((num_recs, ), dtype=list)\n",
    "y = np.zeros((num_recs, ))\n",
    "i = 0\n",
    "ftrain = open(INPUT_FILE, 'rb')\n",
    "for line in ftrain:\n",
    "    label, sentence = line.strip().split(b\"\\t\")\n",
    "    words = nltk.word_tokenize(sentence.decode(\"ascii\", \"ignore\").lower())\n",
    "    seqs = []\n",
    "    for word in words:\n",
    "        if word in word2index:\n",
    "            seqs.append(word2index[word])\n",
    "        else:\n",
    "            seqs.append(word2index[\"UNK\"])\n",
    "    X[i] = seqs\n",
    "    y[i] = int(label)\n",
    "    i += 1\n",
    "ftrain.close()\n",
    "\n",
    "# Pad the sequences (left padded with zeros)\n",
    "X = sequence.pad_sequences(X, maxlen=MAX_SENTENCE_LENGTH)\n",
    "\n",
    "# Split input into training and test\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(Xtrain.shape, Xtest.shape, ytrain.shape, ytest.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model building and compilation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 40, 128)           256256    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 305,729\n",
      "Trainable params: 305,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, EMBEDDING_SIZE, input_length=MAX_SENTENCE_LENGTH))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(HIDDEN_LAYER_SIZE, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "#show the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5668 samples, validate on 1418 samples\n",
      "Epoch 1/10\n",
      "5668/5668 [==============================] - 7s 1ms/step - loss: 0.5033 - acc: 0.7650 - val_loss: 0.2307 - val_acc: 0.9478\n",
      "Epoch 2/10\n",
      "5668/5668 [==============================] - 5s 865us/step - loss: 0.1068 - acc: 0.9741 - val_loss: 0.0789 - val_acc: 0.9746\n",
      "Epoch 3/10\n",
      "5668/5668 [==============================] - 5s 891us/step - loss: 0.0334 - acc: 0.9919 - val_loss: 0.0553 - val_acc: 0.9810\n",
      "Epoch 4/10\n",
      "5668/5668 [==============================] - 5s 884us/step - loss: 0.0152 - acc: 0.9965 - val_loss: 0.0591 - val_acc: 0.9824\n",
      "Epoch 5/10\n",
      "5668/5668 [==============================] - 5s 948us/step - loss: 0.0088 - acc: 0.9979 - val_loss: 0.0437 - val_acc: 0.9894\n",
      "Epoch 6/10\n",
      "5668/5668 [==============================] - 7s 1ms/step - loss: 0.0055 - acc: 0.9991 - val_loss: 0.0519 - val_acc: 0.9873\n",
      "Epoch 7/10\n",
      "5668/5668 [==============================] - 5s 848us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0636 - val_acc: 0.9859\n",
      "Epoch 8/10\n",
      "5668/5668 [==============================] - 5s 818us/step - loss: 0.0029 - acc: 0.9995 - val_loss: 0.0629 - val_acc: 0.9866\n",
      "Epoch 9/10\n",
      "5668/5668 [==============================] - 5s 833us/step - loss: 0.0017 - acc: 0.9998 - val_loss: 0.0648 - val_acc: 0.9866\n",
      "Epoch 10/10\n",
      "5668/5668 [==============================] - 5s 852us/step - loss: 0.0053 - acc: 0.9986 - val_loss: 0.0547 - val_acc: 0.9887\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(Xtrain, ytrain, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, validation_data=(Xtest, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss and accuracy\n",
    "plt.subplot(211)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"g\", label=\"Train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"Validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"g\", label=\"Train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"Validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1418/1418 [==============================] - 0s 326us/step\n",
      "Test score: 0.055, accuracy: 0.989\n",
      "0\t0\tda vinci code sucks .\n",
      "0\t0\tas i sit here , watching the mtv movie awards , i am reminded of how much i despised the movie brokeback mountain .\n",
      "1\t1\ti wanted desperately to love'the da vinci code as a film .\n",
      "0\t0\tby the way , the da vinci code sucked , just letting you know ...\n",
      "0\t0\ti thought brokeback mountain was an awful movie .\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "score, acc = model.evaluate(Xtest, ytest, batch_size=BATCH_SIZE)\n",
    "print(\"Test score: %.3f, accuracy: %.3f\" % (score, acc))\n",
    "\n",
    "for i in range(5):\n",
    "    idx = np.random.randint(len(Xtest))\n",
    "    xtest = Xtest[idx].reshape(1,40)\n",
    "    ylabel = ytest[idx]\n",
    "    ypred = model.predict(xtest)[0][0]\n",
    "    sent = \" \".join([index2word[x] for x in xtest[0].tolist() if x != 0])\n",
    "    print(\"%.0f\\t%d\\t%s\" % (ypred, ylabel, sent))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
